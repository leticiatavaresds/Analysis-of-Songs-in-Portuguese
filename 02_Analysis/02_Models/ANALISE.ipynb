{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:18:08.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mLoading data...\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:12.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mPreparing dataframes for all genres and BR genres...\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:12.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mLoading feature group model for artist...\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:12.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: statistical\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:18:19.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:19.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: statistical_time\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:19.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:19.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: explicitness\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:18:19.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:19.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: pronouns\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:19.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:19.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: postags\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:18:19.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:20.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: lemma\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:20.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:20.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: afinn\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:20.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:20.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: vader\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:18:20.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:20.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: rid\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:18:20.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:20.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: audio\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:18:21.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:21.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: combined\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:18:37.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:37.083\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: combined + audio\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:18:52.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:18:52.422\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m115\u001b[0m - \u001b[32m\u001b[1mResults saved to '../02_Output_Kfold_Models/svc_results_F1_br_genres_more_feats.csv'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3.9\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Author: Let√≠cia Tavares\n",
    "Date: 2024-08-06\n",
    "Version: 1.0.0\n",
    "\n",
    "Description:\n",
    "    This script trains and evaluates a Linear Support Vector Classification (SVC) model using multi-output classification on genre classification data.\n",
    "    It utilizes the `analysis_functions` module to load and prepare the data, perform hyperparameter tuning with Grid Search,\n",
    "    and evaluate the model's performance. The results are saved in a CSV file.\n",
    "\n",
    "    The script performs the following steps:\n",
    "    1. Loads genre classification data using a custom function.\n",
    "    2. Prepares dataframes for all genres and Brazilian genres.\n",
    "    3. Defines and trains a LinearSVC model using multi-output classification with a pipeline that includes scaling.\n",
    "    4. Performs Grid Search with cross-validation to tune hyperparameters.\n",
    "       The parameter grid includes:\n",
    "       - `C`: [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "       - `loss`: ['squared_hinge']\n",
    "    5. Evaluates the model using F1 scores (micro and macro).\n",
    "    6. Saves the results to a CSV file, including the combination of parameters that generates the best result.\n",
    "\n",
    "\n",
    "Usage:\n",
    "    1. Ensure all dependencies are installed and accessible.\n",
    "    2. Ensure the `functions` directory is in the correct path and contains `analysis_functions.py`.\n",
    "    3. Run the script: python 02_SVC_F1_all_genres.py\n",
    "\n",
    "Notes:\n",
    "    - Adjust paths and filenames as needed.\n",
    "    - Results are saved to 'svc_results_F1_all_genres.csv' in the specified output directory.\n",
    "\"\"\"\n",
    "\n",
    "# Standard library imports\n",
    "import os  # Operating system interface\n",
    "import sys  # System-specific parameters and functions\n",
    "\n",
    "# Third-party library imports\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "from loguru import logger  # Logging\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold  # Model selection\n",
    "from sklearn.preprocessing import StandardScaler  # Data preprocessing\n",
    "from sklearn.pipeline import Pipeline  # Pipeline for combining multiple steps\n",
    "from sklearn.svm import LinearSVC  # Support Vector Classification\n",
    "from sklearn.multioutput import MultiOutputClassifier  # Multi-output classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Local application/library specific imports\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Adiciona o caminho relativo ao diret√≥rio 'functions' na lista de caminhos de importa√ß√£o\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(notebook_dir, '../functions')))\n",
    "import analysis_functions\n",
    "from analysis_functions import folder_output\n",
    "\n",
    "\n",
    "# Load data\n",
    "logger.info(\"Loading data...\")\n",
    "df, all_genres, br_genres = analysis_functions.get_data()\n",
    "\n",
    "# Prepare dataframes for all genres and BR genres\n",
    "logger.info(\"Preparing dataframes for all genres and BR genres...\")\n",
    "df_all_genres = analysis_functions.make_df_genres(df, all_genres)\n",
    "df_br_genres = analysis_functions.make_df_genres(df, br_genres)\n",
    "\n",
    "# Load feature group model for artist\n",
    "logger.info(\"Loading feature group model for artist...\")\n",
    "feat_group_model = analysis_functions.dict_feature_group()\n",
    "\n",
    "def train_and_evaluate_linear_svc(X, y, feature_group_name, genres):\n",
    "    logger.info(f\"Training and evaluating LinearSVC for feature group: {feature_group_name}\")\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Define the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LinearSVC())\n",
    "    ])\n",
    "\n",
    "    # Define the hyperparameter grid\n",
    "    param_grid = {\n",
    "        'model__C': [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "        'model__loss': ['squared_hinge']\n",
    "    }\n",
    "\n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, n_jobs=-1,\n",
    "                               scoring=['f1_micro', 'f1_macro'], refit=False,\n",
    "                               verbose=3, return_train_score=True, \n",
    "                               cv=KFold(n_splits=5, shuffle=True, random_state=42))\n",
    "                                \n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model from grid search\n",
    "    results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "    results_df['feature_group'] = feature_group_name\n",
    "\n",
    "    # Join genres into a string\n",
    "    genres = \",\".join(str(element) for element in genres)\n",
    "    results_df['genre_labels'] = genres\n",
    "\n",
    "    logger.info(\"Results compiled into dataframe.\")\n",
    "    return results_df\n",
    "\n",
    "# Execute model training and evaluation for BR genres and all genres\n",
    "# logger.info(\"Executing model training and evaluation for All genres...\")\n",
    "df_results_SVC = analysis_functions.exec_model(train_and_evaluate_linear_svc, df, br_genres, feat_group_model, \"SVC\", False)\n",
    "\n",
    "# Combine results and save to CSV\n",
    "df_results_SVC.to_csv(f'{folder_output}/svc_results_F1_br_genres_more_feats.csv', index=False)\n",
    "logger.success(f\"Results saved to '{folder_output}/svc_results_F1_br_genres_more_feats.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:18:52.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: statistical\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:19:07.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:19:07.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: statistical_time\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:19:07.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:19:07.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: explicitness\u001b[0m\n",
      "\u001b[32m2024-08-06 23:19:07.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:19:07.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: pronouns\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:19:08.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:19:08.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: postags\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:19:09.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:19:09.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: lemma\u001b[0m\n",
      "\u001b[32m2024-08-06 23:19:09.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:19:09.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: afinn\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:19:10.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:19:10.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: vader\u001b[0m\n",
      "\u001b[32m2024-08-06 23:19:10.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:19:10.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: rid\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:19:11.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:19:11.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: audio\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:19:12.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:19:12.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: combined\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:19:49.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:19:49.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: combined + audio\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:20:23.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:20:23.655\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[32m\u001b[1mResults saved to '../02_Output_Kfold_Models/svc_results_F1_all_genres_more_feats.csv'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df_results_SVC = analysis_functions.exec_model(train_and_evaluate_linear_svc, df, all_genres, feat_group_model, \"SVC\", False)\n",
    "\n",
    "# Combine results and save to CSV\n",
    "df_results_SVC.to_csv(f'{folder_output}/svc_results_F1_all_genres_more_feats.csv', index=False)\n",
    "logger.success(f\"Results saved to '{folder_output}/svc_results_F1_all_genres_more_feats.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:20:23.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: statistical\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:20:38.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:20:38.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: statistical_time\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:20:39.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:20:39.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: explicitness\u001b[0m\n",
      "\u001b[32m2024-08-06 23:20:39.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:20:39.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: audio\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 23:20:40.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-06 23:20:43.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: tf-idf\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 00:32:00.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-07 00:32:01.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: lda\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 00:32:03.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-07 00:32:03.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: combined\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 00:32:24.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-07 00:32:25.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: combined (tf-idf + lda)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 01:45:57.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-07 01:45:57.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: combined + audio\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 01:46:31.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-07 01:46:31.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: combined (tf-idf + lda) + audio\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 02:47:33.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-07 02:47:35.101\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[32m\u001b[1mResults saved to '../02_Output_Kfold_Models/svc_results_F1_all_genres.csv'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "feat_group_model = analysis_functions.dict_feature_group_art()\n",
    "\n",
    "df_results_SVC = analysis_functions.exec_model(train_and_evaluate_linear_svc, df, all_genres, feat_group_model, \"SVC\", True)\n",
    "\n",
    "# Combine results and save to CSV\n",
    "df_results_SVC.to_csv(f'{folder_output}/svc_results_F1_all_genres.csv', index=False)\n",
    "logger.success(f\"Results saved to '{folder_output}/svc_results_F1_all_genres.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 11:47:41.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mLoading data...\u001b[0m\n",
      "\u001b[32m2024-08-07 11:47:46.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mPreparing dataframes for all genres and BR genres...\u001b[0m\n",
      "\u001b[32m2024-08-07 11:47:46.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mLoading feature group model for artist...\u001b[0m\n",
      "\u001b[32m2024-08-07 11:47:46.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m164\u001b[0m - \u001b[1mExecuting model training and evaluation for BR genres...\u001b[0m\n",
      "\u001b[32m2024-08-07 11:47:46.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_nn\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTraining and evaluating Neural Network for feature group: statistical\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OIEE\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 12:18:40.044\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_nn\u001b[0m:\u001b[36m159\u001b[0m - \u001b[32m\u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-07 12:18:40.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_nn\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTraining and evaluating Neural Network for feature group: statistical_time\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 12:49:24.320\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_nn\u001b[0m:\u001b[36m159\u001b[0m - \u001b[32m\u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-07 12:49:24.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_nn\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTraining and evaluating Neural Network for feature group: explicitness\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 13:23:59.429\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_nn\u001b[0m:\u001b[36m159\u001b[0m - \u001b[32m\u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-07 13:23:59.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_nn\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTraining and evaluating Neural Network for feature group: pronouns\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 14:16:49.766\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_nn\u001b[0m:\u001b[36m159\u001b[0m - \u001b[32m\u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-07 14:16:49.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_nn\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTraining and evaluating Neural Network for feature group: postags\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 15:13:18.005\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_nn\u001b[0m:\u001b[36m159\u001b[0m - \u001b[32m\u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-07 15:13:18.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_nn\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTraining and evaluating Neural Network for feature group: lemma\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 16:06:42.223\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_nn\u001b[0m:\u001b[36m159\u001b[0m - \u001b[32m\u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-07 16:06:42.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_nn\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTraining and evaluating Neural Network for feature group: afinn\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 16:56:02.070\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_nn\u001b[0m:\u001b[36m159\u001b[0m - \u001b[32m\u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-07 16:56:02.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_nn\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTraining and evaluating Neural Network for feature group: vader\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-07 17:38:33.508\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_nn\u001b[0m:\u001b[36m159\u001b[0m - \u001b[32m\u001b[1mResults compiled into dataframe.\u001b[0m\n",
      "\u001b[32m2024-08-07 17:38:33.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_nn\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTraining and evaluating Neural Network for feature group: rid\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 165\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# Execute model training and evaluation for BR genres\u001b[39;00m\n\u001b[0;32m    164\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuting model training and evaluation for BR genres...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 165\u001b[0m df_results_NN \u001b[38;5;241m=\u001b[39m \u001b[43manalysis_functions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_and_evaluate_nn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbr_genres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat_group_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNeural Network\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# Combine results and save to CSV\u001b[39;00m\n\u001b[0;32m    168\u001b[0m df_results_NN\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/neural_network_results_F1_br_genres_more_feats.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\letic\\Documents\\TCC\\Github\\Analysis-of-Songs-in-Portuguese\\02_Analysis\\functions\\analysis_functions.py:279\u001b[0m, in \u001b[0;36mexec_model\u001b[1;34m(function_model, df, genres, feat_group_model, model, with_vect)\u001b[0m\n\u001b[0;32m    277\u001b[0m     feats \u001b[38;5;241m=\u001b[39m feat_group_model[group_feat]\n\u001b[0;32m    278\u001b[0m     X \u001b[38;5;241m=\u001b[39m filtered_df[feats]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 279\u001b[0m     result_group \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_feat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenres\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m     results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([results_df, result_group], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(with_vect):\n",
      "Cell \u001b[1;32mIn[1], line 125\u001b[0m, in \u001b[0;36mtrain_and_evaluate_nn\u001b[1;34m(X, y, feature_group_name, genres)\u001b[0m\n\u001b[0;32m    122\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m    128\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3.6\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Author: Let√≠cia Tavares\n",
    "Date: 2024-08-06\n",
    "Version: 1.0.0\n",
    "\n",
    "Description:\n",
    "    This script trains and evaluates a Neural Network model for genre classification.\n",
    "    The model is built using TensorFlow and Keras, with multiple dense layers and dropout for regularization.\n",
    "    It utilizes the `analysis_functions` module to load and prepare the data, performs K-Fold cross-validation,\n",
    "    and evaluates the model's performance. The results are saved in a CSV file.\n",
    "\n",
    "    The script performs the following steps:\n",
    "    1. Loads genre classification data using a custom function.\n",
    "    2. Prepares dataframes for all genres and Brazilian genres.\n",
    "    3. Defines and trains a Neural Network model using K-Fold cross-validation with different configurations.\n",
    "    4. Evaluates the model's performance using accuracy and F1 scores.\n",
    "    5. Saves the best results to a CSV file, including the combination of parameters that generates the best result.\n",
    "\n",
    "    Parameters and Combinations:\n",
    "    - Dense Sizes: (32, 32), (64, 64)\n",
    "    - Dropout Rates: 0.1\n",
    "    - Epochs: 50\n",
    "    - Batch Sizes: 2\n",
    "\n",
    "Usage:\n",
    "    1. Ensure all dependencies are installed and accessible.\n",
    "    2. Ensure the `functions` directory is in the correct path and contains `analysis_functions.py`.\n",
    "    3. Run the script: python 02_Neural_Network_F1_br_genres_more_feats.py\n",
    "\n",
    "Notes:\n",
    "    - Adjust paths and filenames as needed.\n",
    "    - Results are saved to 'neural_network_results_F1_br_genres_more_feats.csv' in the specified output directory.\n",
    "\"\"\"\n",
    "\n",
    "# Standard library imports\n",
    "import os  # Operating system interface\n",
    "import sys  # System-specific parameters and functions\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np  # Numerical operations\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "import tensorflow  as tf # Deep learning library\n",
    "from loguru import logger  # Logging\n",
    "from sklearn.preprocessing import StandardScaler  # Data preprocessing\n",
    "from sklearn.model_selection import KFold  # Model selection\n",
    "from sklearn.metrics import accuracy_score, f1_score  # Performance metrics\n",
    "\n",
    "\n",
    "# Adiciona o caminho relativo ao diret√≥rio 'functions' na lista de caminhos de importa√ß√£o\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../functions')))\n",
    "import analysis_functions\n",
    "from analysis_functions import folder_output\n",
    "\n",
    "# Load data\n",
    "logger.info(\"Loading data...\")\n",
    "df, all_genres, br_genres = analysis_functions.get_data()\n",
    "\n",
    "# Prepare dataframes for all genres and BR genres\n",
    "logger.info(\"Preparing dataframes for all genres and BR genres...\")\n",
    "df_all_genres = analysis_functions.make_df_genres(df, all_genres)\n",
    "df_br_genres = analysis_functions.make_df_genres(df, br_genres)\n",
    "\n",
    "# Load feature group model for artist\n",
    "logger.info(\"Loading feature group model for artist...\")\n",
    "feat_group_model = analysis_functions.dict_feature_group()\n",
    "\n",
    "def create_nn_model(dense_sizes=(32, 32), dropout_rate=0.1, input_shape=None, output_shape=None):\n",
    "    inp = tf.keras.layers.Input(shape=(input_shape,))\n",
    "    \n",
    "    # Dense layers\n",
    "    layer = inp\n",
    "    for size in dense_sizes:\n",
    "        layer = tf.keras.layers.Dense(size, activation=\"selu\", kernel_initializer=\"lecun_normal\")(layer)\n",
    "        layer = tf.keras.layers.Dropout(dropout_rate)(layer)\n",
    "\n",
    "    # Output layer\n",
    "    out = tf.keras.layers.Dense(output_shape, activation=\"softmax\")(layer)\n",
    "    \n",
    "    # Create the model\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate_nn(X, y, feature_group_name, genres):\n",
    "    logger.info(f\"Training and evaluating Neural Network for feature group: {feature_group_name}\")\n",
    "\n",
    "    results = []\n",
    "    genres = \",\".join(str(element) for element in genres)\n",
    "\n",
    "    # Parameters\n",
    "    dense_sizes_list = [(32, 32),(64, 64)]\n",
    "    dropout_rates = [0.1]\n",
    "    epochs = 50\n",
    "    batch_size = 2\n",
    "\n",
    "    # Perform K-Fold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Determine the number of classes\n",
    "    output_shape = np.max(y) + 1\n",
    "    \n",
    "    for dense_sizes in dense_sizes_list:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            fold_accuracies = []\n",
    "            fold_f1_micro_scores = []\n",
    "            fold_f1_macro_scores = []\n",
    "\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "                model = create_nn_model(dense_sizes=dense_sizes, dropout_rate=dropout_rate, input_shape=X.shape[1], output_shape = output_shape)\n",
    "                \n",
    "                # Normalize data\n",
    "                scaler = StandardScaler()\n",
    "                X_train_scaled = scaler.fit_transform(X_train)\n",
    "                X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "                # Train the model\n",
    "                model.fit(X_train_scaled, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "                # Evaluate the model\n",
    "                y_pred = model.predict(X_test_scaled)\n",
    "                y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "                f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "                fold_accuracies.append(accuracy)\n",
    "                fold_f1_micro_scores.append(f1_micro)\n",
    "                fold_f1_macro_scores.append(f1_macro)\n",
    "\n",
    "            mean_accuracy = np.mean(fold_accuracies)\n",
    "            mean_f1_micro = np.mean(fold_f1_micro_scores)\n",
    "            mean_f1_macro = np.mean(fold_f1_macro_scores)\n",
    "    \n",
    "            results.append({\n",
    "                'feature_group': feature_group_name,\n",
    "                'params': {'dense_sizes': dense_sizes, 'dropout_rate': dropout_rate, 'epochs': epochs, 'batch_size': batch_size},\n",
    "                'dense_sizes': dense_sizes,\n",
    "                'dropout_rate': dropout_rate,\n",
    "                'mean_accuracy': mean_accuracy,\n",
    "                'mean_test_f1_micro': mean_f1_micro,\n",
    "                'mean_test_f1_macro': mean_f1_macro,\n",
    "                'epochs': epochs,\n",
    "                'batch_size': batch_size,\n",
    "                'genre_labels': genres,\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df['genre_labels'] = genres\n",
    "    \n",
    "    logger.success(\"Results compiled into dataframe.\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Execute model training and evaluation for BR genres\n",
    "logger.info(\"Executing model training and evaluation for BR genres...\")\n",
    "df_results_NN = analysis_functions.exec_model(train_and_evaluate_nn, df, br_genres, feat_group_model, \"Neural Network\", False)\n",
    "\n",
    "# Combine results and save to CSV\n",
    "df_results_NN.to_csv(f'{folder_output}/neural_network_results_F1_br_genres_more_feats.csv', index=False)\n",
    "logger.success(\"Results saved to f'{folder_output}/neural_network_results_F1_br_genres_more_feats_2.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_group_model = analysis_functions.dict_feature_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-08 07:21:48.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mLoading data...\u001b[0m\n",
      "\u001b[32m2024-08-08 07:21:52.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mPreparing dataframes for all genres and BR genres...\u001b[0m\n",
      "\u001b[32m2024-08-08 07:21:52.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m69\u001b[0m - \u001b[1mLoading feature group model for artist...\u001b[0m\n",
      "\u001b[32m2024-08-08 07:21:52.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m111\u001b[0m - \u001b[1mExecuting model training and evaluation for All genres...\u001b[0m\n",
      "\u001b[32m2024-08-08 07:21:52.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_and_evaluate_linear_svc\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mTraining and evaluating LinearSVC for feature group: statistical\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3.9\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Author: Let√≠cia Tavares\n",
    "Date: 2024-08-06\n",
    "Version: 1.0.0\n",
    "\n",
    "Description:\n",
    "    This script trains and evaluates a Linear Support Vector Classification (SVC) model using multi-output classification on genre classification data.\n",
    "    It utilizes the `analysis_functions` module to load and prepare the data, perform hyperparameter tuning with Grid Search,\n",
    "    and evaluate the model's performance. The results are saved in a CSV file.\n",
    "\n",
    "    The script performs the following steps:\n",
    "    1. Loads genre classification data using a custom function.\n",
    "    2. Prepares dataframes for all genres and Brazilian genres.\n",
    "    3. Defines and trains a LinearSVC model using multi-output classification with a pipeline that includes scaling.\n",
    "    4. Performs Grid Search with cross-validation to tune hyperparameters.\n",
    "       The parameter grid includes:\n",
    "       - `C`: [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "       - `loss`: ['squared_hinge']\n",
    "    5. Evaluates the model using F1 scores (micro and macro).\n",
    "    6. Saves the results to a CSV file, including the combination of parameters that generates the best result.\n",
    "\n",
    "\n",
    "Usage:\n",
    "    1. Ensure all dependencies are installed and accessible.\n",
    "    2. Ensure the `functions` directory is in the correct path and contains `analysis_functions.py`.\n",
    "    3. Run the script: python 02_SVC_F1_all_genres_more_feats.py\n",
    "\n",
    "Notes:\n",
    "    - Adjust paths and filenames as needed.\n",
    "    - Results are saved to 'svc_results_F1_all_genres_more_feats.csv' in the specified output directory.\n",
    "\"\"\"\n",
    "\n",
    "# Standard library imports\n",
    "import os  # Operating system interface\n",
    "import sys  # System-specific parameters and functions\n",
    "\n",
    "# Third-party library imports\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "import random # Random number generation and related operations \n",
    "from loguru import logger  # Logging\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold  # Model selection\n",
    "from sklearn.preprocessing import StandardScaler  # Data preprocessing\n",
    "from sklearn.pipeline import Pipeline  # Pipeline for combining multiple steps\n",
    "from sklearn.svm import LinearSVC  # Support Vector Classification\n",
    "from sklearn.multioutput import MultiOutputClassifier  # Multi-output classification\n",
    "\n",
    "# Local application/library specific imports\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../functions')))\n",
    "import analysis_functions\n",
    "from analysis_functions import folder_output\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "\n",
    "# Load data\n",
    "logger.info(\"Loading data...\")\n",
    "df, all_genres, br_genres = analysis_functions.get_data()\n",
    "\n",
    "# Prepare dataframes for all genres and BR genres\n",
    "logger.info(\"Preparing dataframes for all genres and BR genres...\")\n",
    "df_all_genres = analysis_functions.make_df_genres(df, all_genres)\n",
    "df_br_genres = analysis_functions.make_df_genres(df, br_genres)\n",
    "\n",
    "# Load feature group model for artist\n",
    "logger.info(\"Loading feature group model for artist...\")\n",
    "feat_group_model = analysis_functions.dict_feature_group()\n",
    "\n",
    "def train_and_evaluate_linear_svc(X, y, feature_group_name, genres):\n",
    "    logger.info(f\"Training and evaluating LinearSVC for feature group: {feature_group_name}\")\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Define the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LinearSVC(random_state=42)),\n",
    "    ])\n",
    "\n",
    "    # Define the hyperparameter grid\n",
    "    param_grid = {\n",
    "        'model__C': [0.1],\n",
    "        'model__loss': ['squared_hinge']\n",
    "    }\n",
    "\n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, n_jobs=-1,\n",
    "                                scoring=['f1_micro', 'f1_macro'], refit=False,\n",
    "                                verbose=3, return_train_score=True, \n",
    "                                cv=KFold(n_splits=5, shuffle=True, random_state=42))\n",
    "                                \n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model from grid search\n",
    "    results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "    results_df['feature_group'] = feature_group_name\n",
    "\n",
    "    # Join genres into a string\n",
    "    genres = \",\".join(str(element) for element in genres)\n",
    "    results_df['genre_labels'] = genres\n",
    "\n",
    "    logger.success(\"Results compiled into dataframe.\")\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# Execute model training and evaluation for BR genres and all genres\n",
    "logger.info(\"Executing model training and evaluation for All genres...\")\n",
    "df_results_SVC = analysis_functions.exec_model(train_and_evaluate_linear_svc, df, all_genres, feat_group_model, \"SVC\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.470489\n",
       "1     0.472991\n",
       "2     0.467018\n",
       "3     0.447505\n",
       "4     0.389358\n",
       "5     0.384934\n",
       "6     0.316465\n",
       "7     0.326132\n",
       "8     0.311511\n",
       "9     0.315592\n",
       "10    0.281118\n",
       "11    0.279625\n",
       "12    0.285363\n",
       "13    0.279272\n",
       "14    0.207004\n",
       "15    0.207004\n",
       "16    0.230582\n",
       "17    0.232620\n",
       "18    0.211914\n",
       "19    0.211914\n",
       "20    0.224507\n",
       "21    0.223958\n",
       "22    0.040468\n",
       "23    0.040468\n",
       "Name: mean_test_f1_macro, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_SVC.mean_test_f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.470489\n",
       "1     0.472991\n",
       "2     0.467018\n",
       "3     0.447505\n",
       "4     0.389358\n",
       "5     0.384934\n",
       "6     0.316465\n",
       "7     0.326132\n",
       "8     0.311511\n",
       "9     0.315592\n",
       "10    0.281118\n",
       "11    0.279625\n",
       "12    0.285363\n",
       "13    0.279272\n",
       "14    0.207004\n",
       "15    0.207004\n",
       "16    0.230582\n",
       "17    0.232620\n",
       "18    0.211914\n",
       "19    0.211914\n",
       "20    0.224507\n",
       "21    0.223958\n",
       "22    0.040468\n",
       "23    0.040468\n",
       "Name: mean_test_f1_macro, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_SVC.mean_test_f1_macro"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMqyr5G++EUmSYi/PBLek1L",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
